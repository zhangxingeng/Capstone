{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_drive = r\"G:\\.shortcut-targets-by-id\\184tVjsIO-GAjbkSakwDbEZ40M5mPpgu4\\Capstone\\cleaned_data\"\n",
    "google_drive = r\"G:\\My Drive\\Spring_2022\\CS554\\Project\\data\"\n",
    "drive = r\"D:\\Users\\yiboz\\Programming\\Github\\CS554\\data\"\n",
    "articles = pd.read_csv(shared_drive+r\"\\articles_clean.csv\", dtype={'article_id':str})\n",
    "customers = pd.read_csv(shared_drive+r\"\\customers_clean.csv\", dtype={'customer_id':str})\n",
    "transactions = pd.read_csv(shared_drive+r\"\\transactions_train.csv\", dtype={'article_id':str, 'customer_id':str})\n",
    "sample = pd.read_csv(shared_drive+r\"\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Look back again on how the Movie reccomendation rating thing worked, might need 100k+ columns for 1.3mil customers (looking at possibly 10BIL+ rows), regression rating on each. Definetely need pyspark. Using ratings to rank their top 12 preferences \n",
    "\n",
    "\n",
    "Questions: \n",
    "    \n",
    "    1. How to use a list of article_ids as outputs? \n",
    "    2. How to get a list of predictions of article_ids? \n",
    "    \n",
    "    3. How are we supposed to use the transaction date values? Do we want to use it? \n",
    "    4. What are the significant columns in the articles table we wanted to use? Need to use Chi-square to test. \n",
    "    5. Articles have a high cardinality and I need to reduce their dimension? What is the best way to encode the article categories? \n",
    "        - https://pbpython.com/categorical-encoding.html \n",
    "    6. What is the type of regressor I want to use for my ranking data? \n",
    "\n",
    "\n",
    "The Plan: Need to use regression on ratings of all articles? (just use articles from Transactions)  \n",
    "    \n",
    "    Ratings: Get value_counts of each article_id bought and normalize by taking (Max_frequency - Min_frequency) (need pivot table). Answers questions 1 and 2. \n",
    "    \n",
    "    Encoding: Categorical vs Binary due to High Cardinality of article_id \n",
    "    \n",
    "    Buckets: Group customers into buckets of close age brackets (possibly based on the distribution) and other characteristics \n",
    "    \n",
    "    Reduction of Articles: drop the bottom percent of least popular articles\n",
    "    \n",
    "    Reduction of Customers: use only a small percentage of customers to train/test the data, then get recommendations on everyone else \n",
    "    \n",
    "    Regressor: Try 'reg:squarederror', need to look into rank:pairwise and rank:map\n",
    "    \n",
    "    Evaluation: default set by objective function, ex. 'rmse'. \n",
    "\n",
    "TODO: figure out the most significant articles columns, all categorical so use Chi-squared test \n",
    "\n",
    "X-values (did we ever figure out the most significant columns for all of the articles?): ['customer_id', 'age', 'FN', 'Active']\n",
    "\n",
    "    Need to seperate customer and article characteristics for a hybrid approach, possibly combine afterwards \n",
    "\n",
    "Y-values: ratings on all articles \n",
    "\n",
    "Observations: \n",
    "\n",
    "    1. The data is horribly imbalanced, with thousands of users having only purchased one item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: index_group_no size: 5\n"
     ]
    }
   ],
   "source": [
    "# index group is the smallest at 5 different categories \n",
    "mini = sys.maxsize\n",
    "col = ''\n",
    "for i in articles.columns: \n",
    "    n = articles[i].unique().size\n",
    "    if mini > n: \n",
    "        mini = n\n",
    "        col = i\n",
    "print(\"col: \"+col+\" size: \"+ str(mini))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_attributes = ['age', 'FN', 'Active', 'customer_id']\n",
    "article_attributes = ['price', 'index_group_name', 'article_id']\n",
    "target = \"rating\"\n",
    "nums = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27908958</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>4155ad2d5445d70b493129ee1501f38445c62301a6c6d5...</td>\n",
       "      <td>0857855003</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8763190</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>ab4a687ea5bf4d36dadf45c4c7c3ff873fa9856d90ffcb...</td>\n",
       "      <td>0748983002</td>\n",
       "      <td>0.059305</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31409229</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>ec0d5fda8911b4e7a7eb7f77dfdd210c0b9299610d3ee9...</td>\n",
       "      <td>0850917001</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223656</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>e6927a969e181c6392bf7edf8a5a1d92b766123fa218f3...</td>\n",
       "      <td>0690502001</td>\n",
       "      <td>0.152525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31638912</th>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>964d40d4da8c6875af2340291e78e6088dd4a9a06ff67e...</td>\n",
       "      <td>0240561001</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               t_dat                                        customer_id  \\\n",
       "27908958  2020-06-24  4155ad2d5445d70b493129ee1501f38445c62301a6c6d5...   \n",
       "8763190   2019-04-14  ab4a687ea5bf4d36dadf45c4c7c3ff873fa9856d90ffcb...   \n",
       "31409229  2020-09-11  ec0d5fda8911b4e7a7eb7f77dfdd210c0b9299610d3ee9...   \n",
       "5223656   2019-01-20  e6927a969e181c6392bf7edf8a5a1d92b766123fa218f3...   \n",
       "31638912  2020-09-18  964d40d4da8c6875af2340291e78e6088dd4a9a06ff67e...   \n",
       "\n",
       "          article_id     price  sales_channel_id  \n",
       "27908958  0857855003  0.025407                 1  \n",
       "8763190   0748983002  0.059305                 2  \n",
       "31409229  0850917001  0.025407                 2  \n",
       "5223656   0690502001  0.152525                 2  \n",
       "31638912  0240561001  0.010966                 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transactions.sample(frac=0.01)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the number of features necessary for binary encoding \n",
    "# Input: cardinality of feature\n",
    "# Output: float of the number of columns needed to represent it in binary encoding \n",
    "def binary_features(n): \n",
    "    return np.ceil(np.log(n+1)/np.log(2))\n",
    "\n",
    "# Get purchase counts of each article for each customer \n",
    "# Input: df=base dataframe \n",
    "# Output: dataframe with a column for those purchase counts \n",
    "def purchase_count(df, customer=\"customer_id\", projectPath=False): # from Xingeng \n",
    "    customArticlePair = df[[customer, \"article_id\"]].copy()\n",
    "    # customArticlePair.loc[:,\"rating\"] = pd.Series([1 for x in range(len(customArticlePair))]) # Add a column of purchase count\n",
    "    customArticlePair[\"count\"] = 1\n",
    "    # customArticlePair.to_csv(\"/content/gdrive/MyDrive/Capstone/co_filter/customer_article_pair.csv\",index=False)\n",
    "    countGroup = customArticlePair.groupby([customer, \"article_id\"]).count() # count purchase numbers\n",
    "    \n",
    "    if projectPath != False: \n",
    "        countGroup.to_csv(f\"{projectPath}/customer_article_count.csv\") # Save Counts to csv file\n",
    "    return countGroup.reset_index()\n",
    "\n",
    "# get ratings of each article for each customer by taking (article count for customer) / (max count for customer)\n",
    "# Input: df=dataframe with purchase counts \n",
    "# Output: df with 'ratings' column \n",
    "def norm_ratings(df): \n",
    "    tempmax = df.groupby('customer_id')['count'].max().rename(\"temp_max\") # get max for each customer_id \n",
    "    temp = df.merge(tempmax, how='left', on='customer_id') # merge the data together \n",
    "    temp['rating'] = temp['count'] / temp['temp_max'] # get true rating \n",
    "    return temp.drop(['count', 'temp_max' ], axis=1)\n",
    "\n",
    "# get ratings on buckets \n",
    "def get_bucket_ratings(n, goal, projectPath=False):\n",
    "    # Merge transactions and customers data\n",
    "    trans_custs = transactions.merge(customers[customer_attributes].set_index('customer_id'), on='customer_id', how='left')\n",
    "    trans_custs = trans_custs[['customer_id', 'article_id', 'price', 'age', 'FN', 'Active']]\n",
    "    trans_custs['count'] = 1\n",
    "    \n",
    "    # get buckets and the article counts for the buckets \n",
    "    buckets = pd.qcut(trans_custs['age'], n)\n",
    "    buckets_age = trans_custs.groupby([buckets, \"FN\", \"Active\"])['age'].mean().to_frame()\n",
    "    buckets_age = buckets_age.rename(columns={'age': 'mean_age'})\n",
    "    \n",
    "    buckets_count = trans_custs.groupby([buckets, \"FN\", \"Active\", 'article_id'])['count'].sum().to_frame()\n",
    "    merged_buckets = buckets_count.reset_index().merge(buckets_age['mean_age'], on=['age', 'FN', 'Active'], how='left')\n",
    "    age_intervals = merged_buckets['age'].unique() \n",
    "    \n",
    "    # get article ratings for the buckets \n",
    "    tempmax = merged_buckets.groupby([\"age\", \"FN\", \"Active\"])['count'].max().rename(\"temp_max\") # get max for each bucket \n",
    "    temp = merged_buckets.merge(tempmax, how='left', on=[\"age\", \"FN\", \"Active\"]) # merge the max for each bucket \n",
    "    temp[goal] = temp['count'] / temp['temp_max'] # get bucket rating \n",
    "    \n",
    "    ratings = temp.drop(['count', 'temp_max'], axis=1)\n",
    "    art_prices = transactions[['article_id', 'price']].drop_duplicates(subset='article_id')\n",
    "    ratings = ratings.merge(art_prices.set_index('article_id'), on='article_id', how='left') # merge price back in \n",
    "    \n",
    "    if projectPath != False: \n",
    "        result.to_csv(f\"{projectPath}/bucket_ratings.csv\") # Save Counts to csv file\n",
    "    return ratings\n",
    "\n",
    "# map categorical variables to numeric or binary, returns a mapped df and decoder dictionary \n",
    "# Input: df=base dataframe, col=column to create a mapping for, to_bin=map to binary \n",
    "# Output: df with a 'col_mapped' column, decoder dictionary for the mapping \n",
    "def mapper(df, col, to_bin=False): \n",
    "    n = df[col].unique().size\n",
    "    mp = dict.fromkeys(range(n*2))\n",
    "    de = dict.fromkeys(range(n*2))\n",
    "    j = 1 \n",
    "    \n",
    "    if to_bin:\n",
    "        b = str(int(binary_features(n)))\n",
    "        f = \"{:0>\"+b+\"b}\"\n",
    "    \n",
    "    for i in df[col].unique(): \n",
    "        if to_bin: \n",
    "            mp[i] = f.format(j)\n",
    "            de[f.format(j)] = i\n",
    "        else: \n",
    "            mp[i] = j\n",
    "        \n",
    "        j += 1   \n",
    "    df[col+'_mapped'] = df[col].apply(lambda x: mp[x] )\n",
    "    return df, de\n",
    "\n",
    "\n",
    "# creating binary encoding for a column  \n",
    "# Input: df=base dataframe, col=column to encode into binary \n",
    "# Output: dataframe with n columns for binary encoding of a categorical variable, decoder dictionary \n",
    "def binary_encoder(df, col): \n",
    "    encoding = df[col].to_frame().copy() \n",
    "    mapped, de = mapper(encoding, col, to_bin=True)\n",
    "    \n",
    "    f = lambda x: col+'_b_{}'.format(x + 1)\n",
    "    binned = pd.DataFrame(mapped.pop(col+'_mapped').apply(list).values.tolist()).apply(pd.to_numeric).rename(columns=f)\n",
    "    return mapped.join(binned), de\n",
    "    \n",
    "\n",
    "# Raw to train, preps all data for xgboosting \n",
    "# Input: df=base dataframe, att_df=datframe with the user or article attributes, atts=list of attributes, \n",
    "# att_id=column name of attribute, cats=name of categorical variable to encode, goal=name of target column \n",
    "# Output: Dataframe of attributes, dataframe of ratings, decoder dictionary \n",
    "def train_data_prep(df, att_df, atts, att_id, cats, goal): \n",
    "    purchases = purchase_count(df)\n",
    "    normed = norm_ratings(purchases)\n",
    "    cust = att_df[atts].copy().set_index(att_id)\n",
    "    merged_df = normed.merge(cust, how='left', on=att_id).drop(att_id, axis=1)\n",
    "    \n",
    "    encoded, de = binary_encoder(merged_df[cats].to_frame().copy(), cats) \n",
    "    \n",
    "    merged_df = merged_df.join(encoded.drop(cats, axis=1))\n",
    "    y_all = merged_df[goal].to_frame()\n",
    "    X_all = merged_df.drop([goal, cats], axis=1)\n",
    "    \n",
    "    return X_all, y_all, de\n",
    "    #return merged_df\n",
    "    \n",
    "# Raw to train, preps all data for xgboosting \n",
    "# Input: goal=name of target column, cats=list of column string names of categories that need to be encoded \n",
    "# Output: Dataframe of attributes, dataframe of ratings, customer to bucket mapper \n",
    "def train_buckets_prep(n, goal, cats):  \n",
    "    merged_df = get_bucket_ratings(n, goal)\n",
    "    \n",
    "    # encode given categorical variables using binary encoding \n",
    "    des = [] # for encoder debugging purposes \n",
    "    for c in cats: \n",
    "        encoded, de = binary_encoder(merged_df[c].to_frame().copy(), c) \n",
    "        merged_df = merged_df.join(encoded.drop(c, axis=1))\n",
    "        des.append(de)\n",
    "    \n",
    "    merged_df = merged_df.drop('age', axis=1)\n",
    "    y_all = merged_df[goal].to_frame()\n",
    "    X_all = merged_df.drop([goal]+cats, axis=1)\n",
    "    \n",
    "    return X_all, y_all\n",
    "    #return X_all, y_all, des \n",
    "    #return X_all, y_all, des \n",
    "    \n",
    "# Breaks down intervals into group indexes that all customer_ids map onto \n",
    "# Input: df=customers dataframe, n = number of intervals \n",
    "# Output: dataframe with mapping from customer_id to group \n",
    "def grouper(df, n): \n",
    "    i = 0\n",
    "    cg = []\n",
    "    df = df.copy()\n",
    "    df['group'] = 0\n",
    "    \n",
    "    intervals = pd.qcut(df['age'], n)\n",
    "    dfg = df.groupby([intervals, \"FN\", \"Active\"])\n",
    "    \n",
    "    for x in dfg.groups: \n",
    "        gg = dfg.get_group(x)\n",
    "        \n",
    "        gg['group'] = i\n",
    "        cg.append(gg)\n",
    "        i +=1 \n",
    "        \n",
    "    pc = pd.concat(cg)\n",
    "    \n",
    "    return pc[['customer_id', 'group']]\n",
    "\n",
    "# Given prediction test x and test y, get root mean square prediction \n",
    "# Input: x=testing attributes, y=testing ratings \n",
    "# Output: root mean squared error between x and y \n",
    "def test_pred_rms(x, y): \n",
    "    pred = pd.DataFrame(x, columns=['pred'])\n",
    "    \n",
    "    y = y.reset_index()\n",
    "    del y['index']\n",
    "    \n",
    "    result = pd.concat([pred, y], ignore_index=True, axis=1, join='inner')\n",
    "    \n",
    "    f = lambda x: 'p_{}'.format(x + 1)\n",
    "    result = result.rename(columns=f)\n",
    "    result['diff'] = result['p_1'] - result['p_2']\n",
    "    result['square'] = result['diff'] ** 2 \n",
    "\n",
    "    return np.sqrt(result['square'].mean()) \n",
    "\n",
    "# prepares the data for a user ID for prediction in the finished model \n",
    "# Input: user=string of customer_id, encoded_articles=pre-built dataframe of all unique articles in the set\n",
    "# Output: customer attributes with encoded, dataframe of customer and article IDs for decoding \n",
    "def test_user_prep(user, encoded_articles):\n",
    "    cust = encoded_articles.copy()\n",
    "    cust['customer_id'] = user \n",
    "    \n",
    "    ids = cust[['customer_id', 'article_id']].copy() # create a frame to easily remap customers and articles  \n",
    "    \n",
    "    cust = cust.merge(customers[customer_attributes].set_index('customer_id'), on='customer_id', how='left')\n",
    "    cust = cust[['age', 'FN', 'Active']+[c for c in cust if c not in ['age', 'FN', 'Active']]]\n",
    "    \n",
    "    return cust.drop(['customer_id', 'article_id'], axis=1), ids\n",
    "  \n",
    "\n",
    "# Turn prediction values into a recommendation for a single user \n",
    "# Input: df=predicted rating scores, ids=decoding IDs for customers and articles, n=top number of ratings to get \n",
    "# Output: dataframe with recommendation in submission form \n",
    "def get_user_rec(df, ids, n):\n",
    "    \n",
    "    pred = pd.DataFrame(df, columns=['rating']).copy()\n",
    "    top12 = pred.sort_values([\"rating\"], ascending=False).head(n)\n",
    "    joined = ids.reset_index().merge(top12, left_on='index', right_on=top12.index, how='inner')\n",
    "    rec = pd.DataFrame(joined.groupby(by='customer_id').apply(agg_articles)).reset_index().rename(columns={0:'prediction'})\n",
    "    \n",
    "    return rec \n",
    "    \n",
    "# aggregate top articles into \n",
    "# Input: df=dataframe of top articles \n",
    "# Output: string of those articles in submission form \n",
    "def agg_articles(df): \n",
    "    return ' '.join(df['article_id'].tolist())   \n",
    "\n",
    "# prep all the buckets \n",
    "\n",
    "def test_all_prep(n, model):\n",
    "    \n",
    "    arts = pd.DataFrame(transactions['article_id'].unique(), columns=['article_id'])\n",
    "    encoded_articles, dec = binary_encoder(arts, 'article_id')\n",
    "    \n",
    "    art_prices = transactions[['article_id', 'price']].drop_duplicates(subset='article_id')\n",
    "    encoded_articles = encoded_articles.merge(art_prices.set_index('article_id'), on='article_id', how='left') # merge price back in \n",
    "    \n",
    "    i = 0\n",
    "    customers['group'] = 0\n",
    "    intervals = pd.qcut(customers['age'], n)\n",
    "    dfg = customers.groupby([intervals, \"FN\", \"Active\"])\n",
    "    \n",
    "    recs = []\n",
    "    for x in dfg.groups:  \n",
    "        gg = dfg.get_group(x).copy()\n",
    "        gg['group'] = i\n",
    "        gg['mean_age'] = gg['age'].mean()\n",
    "        tb, ids = test_bucket_prep(gg, encoded_articles)\n",
    "        \n",
    "        pred = model.predict(tb)\n",
    "        \n",
    "        recs.append(get_bucket_rec(pred,ids,12))\n",
    "        i += 1\n",
    "        \n",
    "    return pd.concat(recs)\n",
    "\n",
    "# prep the articles for each individual bucket\n",
    "# Input: df=split out bucket, encoded_articles=copy of all binary encoded articles \n",
    "def test_bucket_prep(df, encoded_articles):\n",
    "    cust = encoded_articles.copy()\n",
    "    \n",
    "    cust['mean_age'] = df['mean_age'].iloc[0]\n",
    "    cust['FN'] = df['FN'].iloc[0]\n",
    "    cust['Active'] = df['Active'].iloc[0]\n",
    "    cust['group'] = df['group'].iloc[0]\n",
    "\n",
    "    ids = cust[['group', 'article_id']].copy() # create a frame to easily remap customers and articles  \n",
    "    \n",
    "    #cust = cust.merge(customers[customer_attributes].set_index('customer_id'), on='customer_id', how='left')\n",
    "    cust = cust[['mean_age', 'FN', 'Active', 'price']+[c for c in cust if c not in ['mean_age', 'FN', 'Active', 'price']]]\n",
    "    \n",
    "    return cust.drop(['group', 'article_id'], axis=1), ids\n",
    "\n",
    "# for an individual bucket, get a recommendation \n",
    "def get_bucket_rec(df, ids, n): \n",
    "    \n",
    "    pred = pd.DataFrame(df, columns=['rating']).copy()\n",
    "    top12 = pred.sort_values([\"rating\"], ascending=False).head(n)\n",
    "    joined = ids.reset_index().merge(top12, left_on='index', right_on=top12.index, how='inner')\n",
    "    rec = pd.DataFrame(joined.groupby(by='group').apply(agg_articles)).reset_index().rename(columns={0:'prediction'})\n",
    "    \n",
    "    return rec \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ratings'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7832/4061167884.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data_prep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustomers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustomer_attributes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"customer_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'article_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ratings\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7832/746682916.py\u001b[0m in \u001b[0;36mtrain_data_prep\u001b[1;34m(df, att_df, atts, att_id, cats, goal)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mmerged_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[0my_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0mX_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ratings'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def run_model(x, y, n): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=n)\n",
    "    xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=13,random_state=n,n_estimators=100)\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train, \n",
    "              verbose=True, \n",
    "              eval_metric = 'rmse')\n",
    "              \n",
    "    \n",
    "X_all, y_all, de = train_data_prep(df, customers, customer_attributes, \"customer_id\", 'article_id', \"ratings\")\n",
    "X_all.head()\n",
    "\"\"\"    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>mean_age</th>\n",
       "      <th>price</th>\n",
       "      <th>article_id_b_1</th>\n",
       "      <th>article_id_b_2</th>\n",
       "      <th>article_id_b_3</th>\n",
       "      <th>article_id_b_4</th>\n",
       "      <th>article_id_b_5</th>\n",
       "      <th>article_id_b_6</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id_b_8</th>\n",
       "      <th>article_id_b_9</th>\n",
       "      <th>article_id_b_10</th>\n",
       "      <th>article_id_b_11</th>\n",
       "      <th>article_id_b_12</th>\n",
       "      <th>article_id_b_13</th>\n",
       "      <th>article_id_b_14</th>\n",
       "      <th>article_id_b_15</th>\n",
       "      <th>article_id_b_16</th>\n",
       "      <th>article_id_b_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.242112</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.242112</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.242112</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.242112</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.242112</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FN  Active   mean_age     price  article_id_b_1  article_id_b_2  \\\n",
       "0  0.0     0.0  22.242112  0.008458               0               0   \n",
       "1  0.0     0.0  22.242112  0.008458               0               0   \n",
       "2  0.0     0.0  22.242112  0.005068               0               0   \n",
       "3  0.0     0.0  22.242112  0.022864               0               0   \n",
       "4  0.0     0.0  22.242112  0.025407               0               0   \n",
       "\n",
       "   article_id_b_3  article_id_b_4  article_id_b_5  article_id_b_6  ...  \\\n",
       "0               0               0               0               0  ...   \n",
       "1               0               0               0               0  ...   \n",
       "2               0               0               0               0  ...   \n",
       "3               0               0               0               0  ...   \n",
       "4               0               0               0               0  ...   \n",
       "\n",
       "   article_id_b_8  article_id_b_9  article_id_b_10  article_id_b_11  \\\n",
       "0               0               0                0                0   \n",
       "1               0               0                0                0   \n",
       "2               0               0                0                0   \n",
       "3               0               0                0                0   \n",
       "4               0               0                0                0   \n",
       "\n",
       "   article_id_b_12  article_id_b_13  article_id_b_14  article_id_b_15  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                1   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   article_id_b_16  article_id_b_17  \n",
       "0                0                1  \n",
       "1                1                0  \n",
       "2                1                1  \n",
       "3                0                0  \n",
       "4                0                1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all, y_all = train_buckets_prep(nums, target, ['article_id'])\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating\n",
       "0  0.115385\n",
       "1  0.000000\n",
       "2  0.000000\n",
       "3  0.076923\n",
       "4  0.000000"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=13,random_state=42,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=13,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train, \n",
    "              verbose=True, \n",
    "              eval_metric = 'rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01857851364855305"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_rms(pred1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yiboz\\AppData\\Local\\Temp/ipykernel_7832/1729642674.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gg['group'] = i\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>003667a105459b8e9aaa0a9434a2f48e2d9fba489da123...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>021c897da6d36da705952b4ecc46e641b811e094d67f68...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12395</th>\n",
       "      <td>024f985e61d949356e0e6fab6f59a669fc779d9f6c11fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14681</th>\n",
       "      <td>02ba549fb1b6e18685703a22a819af82abd4a0e2b2dc82...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14821</th>\n",
       "      <td>02c17f123da8edcc6af4662151670c874fb991ce76f7a9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371905</th>\n",
       "      <td>fffbf3d9ceedbdfa3e41b8851b8e3ae21267befac31d00...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371920</th>\n",
       "      <td>fffcb073cfbea83431228195820e21c82b56905b3ee1eb...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371938</th>\n",
       "      <td>fffdaa06e7f3e9698fb1df460b03ca6cc56528b98982c5...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371947</th>\n",
       "      <td>fffe61b99c2d0418ed22190a8490b142247e8897c67941...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371949</th>\n",
       "      <td>fffe7116f9f68e8ad287fd7b6e33aad4871d7080e77d2d...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_id  group\n",
       "1152     003667a105459b8e9aaa0a9434a2f48e2d9fba489da123...      0\n",
       "11359    021c897da6d36da705952b4ecc46e641b811e094d67f68...      0\n",
       "12395    024f985e61d949356e0e6fab6f59a669fc779d9f6c11fe...      0\n",
       "14681    02ba549fb1b6e18685703a22a819af82abd4a0e2b2dc82...      0\n",
       "14821    02c17f123da8edcc6af4662151670c874fb991ce76f7a9...      0\n",
       "...                                                    ...    ...\n",
       "1371905  fffbf3d9ceedbdfa3e41b8851b8e3ae21267befac31d00...     15\n",
       "1371920  fffcb073cfbea83431228195820e21c82b56905b3ee1eb...     15\n",
       "1371938  fffdaa06e7f3e9698fb1df460b03ca6cc56528b98982c5...     15\n",
       "1371947  fffe61b99c2d0418ed22190a8490b142247e8897c67941...     15\n",
       "1371949  fffe7116f9f68e8ad287fd7b6e33aad4871d7080e77d2d...     15\n",
       "\n",
       "[1371980 rows x 2 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gm = grouper(customers,nums)\n",
    "gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  group\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...      9\n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...      5\n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...      1\n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...     13\n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...     15"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = sample['customer_id'].to_frame().merge(gm.set_index('customer_id'), on='customer_id', how='inner')\n",
    "sam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group                                         prediction\n",
       "0      0  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0      1  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0      2  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0      3  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0      4  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0      5  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0      6  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0      7  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0      8  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0      9  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0     10  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0     11  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0     12  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0     13  0722437003 0741356002 0783707028 0783707004 07...\n",
       "0     14  0156231001 0111586001 0722437003 0673214001 07...\n",
       "0     15  0156231001 0111586001 0722437003 0673214001 07..."
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = test_all_prep(nums, xgb_model)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371975</th>\n",
       "      <td>ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371976</th>\n",
       "      <td>ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371977</th>\n",
       "      <td>ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371978</th>\n",
       "      <td>ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...</td>\n",
       "      <td>0156231001 0111586001 0722437003 0673214001 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371979</th>\n",
       "      <td>ffffd9ac14e89946416d80e791d064701994755c3ab686...</td>\n",
       "      <td>0722437003 0741356002 0783707028 0783707004 07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               customer_id  \\\n",
       "0        00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1        0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2        000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3        00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4        00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "...                                                    ...   \n",
       "1371975  ffffbbf78b6eaac697a8a5dfbfd2bfa8113ee5b403e474...   \n",
       "1371976  ffffcd5046a6143d29a04fb8c424ce494a76e5cdf4fab5...   \n",
       "1371977  ffffcf35913a0bee60e8741cb2b4e78b8a98ee5ff2e6a1...   \n",
       "1371978  ffffd7744cebcf3aca44ae7049d2a94b87074c3d4ffe38...   \n",
       "1371979  ffffd9ac14e89946416d80e791d064701994755c3ab686...   \n",
       "\n",
       "                                                prediction  \n",
       "0        0722437003 0741356002 0783707028 0783707004 07...  \n",
       "1        0722437003 0741356002 0783707028 0783707004 07...  \n",
       "2        0722437003 0741356002 0783707028 0783707004 07...  \n",
       "3        0722437003 0741356002 0783707028 0783707004 07...  \n",
       "4        0156231001 0111586001 0722437003 0673214001 07...  \n",
       "...                                                    ...  \n",
       "1371975  0722437003 0741356002 0783707028 0783707004 07...  \n",
       "1371976  0722437003 0741356002 0783707028 0783707004 07...  \n",
       "1371977  0156231001 0111586001 0722437003 0673214001 07...  \n",
       "1371978  0156231001 0111586001 0722437003 0673214001 07...  \n",
       "1371979  0722437003 0741356002 0783707028 0783707004 07...  \n",
       "\n",
       "[1371980 rows x 2 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = sam.merge(recs.set_index('group'), how='left', on='group').drop(columns='group', axis=1)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\yiboz\\Github\\Spring 2022\\CS554\\Project\\submissions\" \n",
    "\n",
    "dt = datetime.now().strftime(\"%d-%m-%Y_%H\")\n",
    "compression_opts = dict(method='zip', archive_name='submission.csv')  \n",
    "sub.to_csv(path+r\"\\submission\"+dt+\".zip\", index=False, compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Grouping buckets testing code \n",
    "\n",
    "buckets = pd.qcut(trans_custs['age'], 4)\n",
    "cust_map = tc.groupby([buckets, \"FN\", \"Active\"] )['customer_id'].unique()\n",
    "cust_frame = pd.DataFrame(cust_map)\n",
    "pd.DataFrame(cust_map.values.tolist()).transpose()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
