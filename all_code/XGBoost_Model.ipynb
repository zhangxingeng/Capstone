{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_drive = r\"G:\\.shortcut-targets-by-id\\184tVjsIO-GAjbkSakwDbEZ40M5mPpgu4\\Capstone\\cleaned_data\"\n",
    "google_drive = r\"G:\\My Drive\\Spring_2022\\CS554\\Project\\data\"\n",
    "drive = r\"D:\\Users\\yiboz\\Programming\\Github\\CS554\\data\"\n",
    "articles = pd.read_csv(shared_drive+r\"\\articles_clean.csv\", dtype={'article_id':str})\n",
    "customers = pd.read_csv(shared_drive+r\"\\customers_clean.csv\", dtype={'customer_id':str})\n",
    "transactions = pd.read_csv(shared_drive+r\"\\transactions_train.csv\", dtype={'article_id':str, 'customer_id':str})\n",
    "sample = pd.read_csv(shared_drive+r\"\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...</td>\n",
       "      <td>0706016001 0706016002 0372860001 0610776002 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...</td>\n",
       "      <td>0706016001 0706016002 0372860001 0610776002 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...</td>\n",
       "      <td>0706016001 0706016002 0372860001 0610776002 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...</td>\n",
       "      <td>0706016001 0706016002 0372860001 0610776002 07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...</td>\n",
       "      <td>0706016001 0706016002 0372860001 0610776002 07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id  \\\n",
       "0  00000dbacae5abe5e23885899a1fa44253a17956c6d1c3...   \n",
       "1  0000423b00ade91418cceaf3b26c6af3dd342b51fd051e...   \n",
       "2  000058a12d5b43e67d225668fa1f8d618c13dc232df0ca...   \n",
       "3  00005ca1c9ed5f5146b52ac8639a40ca9d57aeff4d1bd2...   \n",
       "4  00006413d8573cd20ed7128e53b7b13819fe5cfc2d801f...   \n",
       "\n",
       "                                          prediction  \n",
       "0  0706016001 0706016002 0372860001 0610776002 07...  \n",
       "1  0706016001 0706016002 0372860001 0610776002 07...  \n",
       "2  0706016001 0706016002 0372860001 0610776002 07...  \n",
       "3  0706016001 0706016002 0372860001 0610776002 07...  \n",
       "4  0706016001 0706016002 0372860001 0610776002 07...  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0706016001 0706016002 0372860001 0610776002 0759871002 0464297007 0372860002 0610776001 0399223001 0706016003 0720125001 0156231001'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['prediction'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Look back again on how the Movie reccomendation rating thing worked, might need 100k+ columns for 1.3mil customers (looking at possibly 10BIL+ rows), regression rating on each. Definetely need pyspark. Using ratings to rank their top 12 preferences \n",
    "\n",
    "\n",
    "Questions: \n",
    "    \n",
    "    1. How to use a list of article_ids as outputs? \n",
    "    2. How to get a list of predictions of article_ids? \n",
    "    \n",
    "    3. How are we supposed to use the transaction date values? Do we want to use it? \n",
    "    4. What are the significant columns in the articles table we wanted to use? Need to use Chi-square to test. \n",
    "    5. Articles have a high cardinality and I need to reduce their dimension? What is the best way to encode the article categories? \n",
    "        - https://pbpython.com/categorical-encoding.html \n",
    "    6. What is the type of regressor I want to use for my ranking data? \n",
    "\n",
    "\n",
    "The Plan: Need to use regression on ratings of all articles? (just use articles from Transactions)  \n",
    "    \n",
    "    Ratings: Get value_counts of each article_id bought and normalize by taking (Max_frequency - Min_frequency) (need pivot table). Answers questions 1 and 2. \n",
    "    \n",
    "    Encoding: Categorical vs Binary due to High Cardinality of article_id \n",
    "    \n",
    "    Buckets: Group customers into buckets of close age brackets (possibly based on the distribution) and other characteristics \n",
    "    \n",
    "    Reduction of Articles: drop the bottom percent of least popular articles\n",
    "    \n",
    "    Reduction of Customers: use only a small percentage of customers to train/test the data, then get recommendations on everyone else \n",
    "    \n",
    "    Regressor: Try 'reg:squarederror', need to look into rank:pairwise and rank:map\n",
    "    \n",
    "    Evaluation: default set by objective function, ex. 'rmse'. \n",
    "\n",
    "TODO: figure out the most significant articles columns, all categorical so use Chi-squared test \n",
    "\n",
    "X-values (did we ever figure out the most significant columns for all of the articles?): ['customer_id', 'age', 'FN', 'Active']\n",
    "\n",
    "    Need to seperate customer and article characteristics for a hybrid approach, possibly combine afterwards \n",
    "\n",
    "Y-values: ratings on all articles \n",
    "\n",
    "Observations: \n",
    "\n",
    "    1. The data is horribly imbalanced, with thousands of users having only purchased one item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col: index_group_no size: 5\n"
     ]
    }
   ],
   "source": [
    "# index group is the smallest at 5 different categories \n",
    "mini = sys.maxsize\n",
    "col = ''\n",
    "for i in articles.columns: \n",
    "    n = articles[i].unique().size\n",
    "    if mini > n: \n",
    "        mini = n\n",
    "        col = i\n",
    "print(\"col: \"+col+\" size: \"+ str(mini))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_attributes = ['age', 'FN', 'Active']\n",
    "article_attributes = ['price', 'index_group_name']\n",
    "target = \"rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_dat</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "      <th>sales_channel_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14603869</th>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>0e5b3379c1c3fc68cd905070104f6aab53c493299e893a...</td>\n",
       "      <td>0531615001</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901204</th>\n",
       "      <td>2019-01-12</td>\n",
       "      <td>74bd41da228573d992e2e3cf26814e7817667b4d09d3cd...</td>\n",
       "      <td>0704629002</td>\n",
       "      <td>0.047441</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8411446</th>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>b1eda66468fb21b6f29022c341a15c1c2dfc080ba0aae3...</td>\n",
       "      <td>0732429001</td>\n",
       "      <td>0.094898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31739575</th>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>8156c342e1c0c61eb1e603a74fb7788ef32204538c0ae4...</td>\n",
       "      <td>0874754003</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24837418</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>0e8e816a0c019b94a174776e7d6d30520d7a140b2204d8...</td>\n",
       "      <td>0837306003</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               t_dat                                        customer_id  \\\n",
       "14603869  2019-07-27  0e5b3379c1c3fc68cd905070104f6aab53c493299e893a...   \n",
       "4901204   2019-01-12  74bd41da228573d992e2e3cf26814e7817667b4d09d3cd...   \n",
       "8411446   2019-04-06  b1eda66468fb21b6f29022c341a15c1c2dfc080ba0aae3...   \n",
       "31739575  2020-09-21  8156c342e1c0c61eb1e603a74fb7788ef32204538c0ae4...   \n",
       "24837418  2020-04-20  0e8e816a0c019b94a174776e7d6d30520d7a140b2204d8...   \n",
       "\n",
       "          article_id     price  sales_channel_id  \n",
       "14603869  0531615001  0.011847                 2  \n",
       "4901204   0704629002  0.047441                 2  \n",
       "8411446   0732429001  0.094898                 2  \n",
       "31739575  0874754003  0.033881                 2  \n",
       "24837418  0837306003  0.033881                 2  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transactions.sample(frac=0.01)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the number of features necessary for binary encoding \n",
    "def binary_features(n): \n",
    "    return np.ceil(np.log(n+1)/np.log(2))\n",
    "\n",
    "def purchase_count(df, customer=\"customer_id\", projectPath=False): # from Xingeng \n",
    "    customArticlePair = df[[customer, \"article_id\"]].copy()\n",
    "    # customArticlePair.loc[:,\"rating\"] = pd.Series([1 for x in range(len(customArticlePair))]) # Add a column of purchase count\n",
    "    customArticlePair[\"count\"] = 1\n",
    "    # customArticlePair.to_csv(\"/content/gdrive/MyDrive/Capstone/co_filter/customer_article_pair.csv\",index=False)\n",
    "    countGroup = customArticlePair.groupby([customer, \"article_id\"]).count() # count purchase numbers\n",
    "    \n",
    "    if projectPath != False: \n",
    "        countGroup.to_csv(f\"{projectPath}/customer_article_count.csv\") # Save Counts to csv file\n",
    "    return countGroup.reset_index()\n",
    "\n",
    "def pivot_norm_purchase_count(df, customer=\"customer_id\"): # from Xingeng \n",
    "    df_matrix = pd.pivot_table(df, values='rating', index=customer, columns='article_id')\n",
    "    df_matrix_norm = (df_matrix-df_matrix.min())/(df_matrix.max()-df_matrix.min())\n",
    "    d = df_matrix_norm.reset_index()\n",
    "    # print(d.head())\n",
    "    # d.index.names = ['scaled_purchase_freq']\n",
    "    # return pd.melt(d, id_vars=['customerId'], value_name='scaled_purchase_freq').dropna()\n",
    "    \n",
    "    return d\n",
    "\n",
    "# get ratings of each article for each customer by taking (article count for customer) / (max count for customer)\n",
    "def norm_ratings(df): \n",
    "    tempmax = df.groupby('customer_id')['count'].max().rename(\"temp_max\") # get max for each customer_id \n",
    "    temp = df.merge(tempmax, how='left', on='customer_id') # merge the data together \n",
    "    temp['rating'] = temp['count'] / temp['temp_max'] # get true rating \n",
    "    return temp.drop(['count', 'temp_max' ], axis=1)\n",
    "\n",
    "def mapper(df, col, to_bin=False): \n",
    "    n = df[col].unique().size\n",
    "    mp = dict.fromkeys(range(n*2))\n",
    "    de = dict.fromkeys(range(n*2))\n",
    "    j = 1 \n",
    "    \n",
    "    if to_bin:\n",
    "        b = str(int(binary_features(n)))\n",
    "        f = \"{:0>\"+b+\"b}\"\n",
    "    \n",
    "    for i in df[col].unique(): \n",
    "        if to_bin: \n",
    "            mp[i] = f.format(j)\n",
    "            de[f.format(j)] = i\n",
    "        else: \n",
    "            mp[i] = j\n",
    "        \n",
    "        j += 1   \n",
    "    df[col+'_mapped'] = df[col].apply(lambda x: mp[x] )\n",
    "    return df, de\n",
    "\n",
    "\n",
    "# creating binary encoding for a column  \n",
    "def binary_encoder(df, col): \n",
    "    encoding = df[col].to_frame().copy() \n",
    "    mapped, de = mapper(encoding, col, to_bin=True)\n",
    "    \n",
    "    f = lambda x: col+'_b_{}'.format(x + 1)\n",
    "    binned = pd.DataFrame(mapped.pop(col+'_mapped').apply(list).values.tolist()).apply(pd.to_numeric).rename(columns=f)\n",
    "    return mapped.join(binned), de\n",
    "    \n",
    "\n",
    "    \n",
    "def data_prep(df, att_df, atts, att_id, cats, goal): \n",
    "    purchases = purchase_count(df)\n",
    "    normed = norm_ratings(purchases)\n",
    "    cust = att_df[[att_id]+atts].copy().set_index(att_id)\n",
    "    merged_df = normed.merge(cust, how='left', on=att_id).drop(att_id, axis=1)\n",
    "    \n",
    "    encoded, de = binary_encoder(merged_df[cats].to_frame().copy(), cats) \n",
    "    \n",
    "    merged_df = merged_df.join(encoded.drop(cats, axis=1))\n",
    "    y_all = merged_df[goal].to_frame()\n",
    "    X_all = merged_df.drop([goal, cats], axis=1)\n",
    "    \n",
    "    return X_all, y_all, de\n",
    "    #return merged_df\n",
    "\n",
    "def test_pred_rms(x, y): \n",
    "    pred = pd.DataFrame(x, columns=['pred'])\n",
    "    \n",
    "    y = y.reset_index()\n",
    "    del y['index']\n",
    "    \n",
    "    result = pd.concat([pred, y], ignore_index=True, axis=1, join='inner')\n",
    "    \n",
    "    f = lambda x: 'p_{}'.format(x + 1)\n",
    "    result = result.rename(columns=f)\n",
    "    result['diff'] = result['p_1'] - result['p_2']\n",
    "    result['square'] = result['diff'] ** 2 \n",
    "\n",
    "    return np.sqrt(result['square'].mean()) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>FN</th>\n",
       "      <th>Active</th>\n",
       "      <th>article_id_b_1</th>\n",
       "      <th>article_id_b_2</th>\n",
       "      <th>article_id_b_3</th>\n",
       "      <th>article_id_b_4</th>\n",
       "      <th>article_id_b_5</th>\n",
       "      <th>article_id_b_6</th>\n",
       "      <th>article_id_b_7</th>\n",
       "      <th>article_id_b_8</th>\n",
       "      <th>article_id_b_9</th>\n",
       "      <th>article_id_b_10</th>\n",
       "      <th>article_id_b_11</th>\n",
       "      <th>article_id_b_12</th>\n",
       "      <th>article_id_b_13</th>\n",
       "      <th>article_id_b_14</th>\n",
       "      <th>article_id_b_15</th>\n",
       "      <th>article_id_b_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age   FN  Active  article_id_b_1  article_id_b_2  article_id_b_3  \\\n",
       "0  24.0  0.0     1.0               0               0               0   \n",
       "1  52.0  1.0     1.0               0               0               0   \n",
       "2  32.0  1.0     1.0               0               0               0   \n",
       "3  56.0  1.0     1.0               0               0               0   \n",
       "4  56.0  1.0     1.0               0               0               0   \n",
       "\n",
       "   article_id_b_4  article_id_b_5  article_id_b_6  article_id_b_7  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   article_id_b_8  article_id_b_9  article_id_b_10  article_id_b_11  \\\n",
       "0               0               0                0                0   \n",
       "1               0               0                0                0   \n",
       "2               0               0                0                0   \n",
       "3               0               0                0                0   \n",
       "4               0               0                0                0   \n",
       "\n",
       "   article_id_b_12  article_id_b_13  article_id_b_14  article_id_b_15  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                1   \n",
       "2                0                0                0                1   \n",
       "3                0                0                1                0   \n",
       "4                0                0                1                0   \n",
       "\n",
       "   article_id_b_16  \n",
       "0                1  \n",
       "1                0  \n",
       "2                1  \n",
       "3                0  \n",
       "4                1  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all, y_all, de = data_prep(df, customers, customer_attributes, \"customer_id\", 'article_id', target)\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_jobs=13,random_state=42,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=13,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train, \n",
    "              verbose=True, \n",
    "              eval_metric = 'rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024915172550973627"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_rms(pred1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT STEP: \n",
    "1. Process all users for their ratings on all articles of clothing \n",
    "2. Get articles with the top 12 ratings, decode the article info \n",
    "3. Create a submission, concat the articles into a string \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = articles['article_id'].count()\n",
    "b = transactions['article_id'].unique().size\n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "be1981ab818cf4ef6765b2ecaea7a2cbf14ccd6e8a7ee985513d9e8e53c6d91b    1895\n",
       "b4db5e5259234574edfff958e170fe3a5e13b6f146752ca066abca3c156acc71    1441\n",
       "49beaacac0c7801c2ce2d189efe525fe80b5d37e46ed05b50a4cd88e34d0748f    1364\n",
       "a65f77281a528bf5c1e9f270141d601d116e1df33bf9df512f495ee06647a9cc    1361\n",
       "cd04ec2726dd58a8c753e0d6423e57716fd9ebcf2f14ed6012e7e5bea016b4d6    1237\n",
       "                                                                    ... \n",
       "63b70b71291668f0a63ade8e321fb3eccb80eba164f2087dad471de065f18e1f       1\n",
       "950b172c36d169bf427545991fe66371f21a085799b44780fdcb2da6a3091613       1\n",
       "7c284f13f4af9d6a53f97279381638ed0cb7afaa4fd4f3eaadc21993ea45fc69       1\n",
       "62d49d0ae11a4f65fa31e354cb87f6b557ebec648e0e5e71435d2dd190d1ccc4       1\n",
       "268eaa31a07d6f2f4f060bfcf32a660f3ea3dbb21ef14cd09fc2545f4e0b5c10       1\n",
       "Name: customer_id, Length: 1362281, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions['customer_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = 'be1981ab818cf4ef6765b2ecaea7a2cbf14ccd6e8a7ee985513d9e8e53c6d91b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = transactions.loc[(transactions['customer_id'] == big)]['article_id'].count()\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253448001    8\n",
       "826500008    7\n",
       "668956001    7\n",
       "828934001    6\n",
       "777099001    6\n",
       "            ..\n",
       "562245089    1\n",
       "680262004    1\n",
       "807064003    1\n",
       "798579002    1\n",
       "879291001    1\n",
       "Name: article_id, Length: 1346, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.loc[(transactions['customer_id'] == big)]['article_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "706016001    480\n",
       "706016002    404\n",
       "372860001    321\n",
       "610776002    286\n",
       "372860002    255\n",
       "            ... \n",
       "614423001      1\n",
       "613666002      1\n",
       "776087001      1\n",
       "636868001      1\n",
       "730683013      1\n",
       "Name: article_id, Length: 53537, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.article_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "be1981ab818cf4ef6765b2ecaea7a2cbf14ccd6e8a7ee985513d9e8e53c6d91b    23\n",
       "67931690bdf18d2e328854ae772cd5ce2505fdc11164693998b13e706db0bb56    21\n",
       "a65f77281a528bf5c1e9f270141d601d116e1df33bf9df512f495ee06647a9cc    18\n",
       "a76cf5ea515d09f22b7fe3e8ea3c1944316bd6264a90e26cef126242ef3c5e11    17\n",
       "03d0011487606c37c1b1ed147fc72f285a50c05f00b9712e0fc3da400c864296    17\n",
       "                                                                    ..\n",
       "328476e33eb9a28207809832497cef3e7ea0e0d5b5f7f302c51fd24d63ae6653     1\n",
       "6b6c4268ceba96e1858768dc56acb4b44c0be24b96aa50df0d90785629301374     1\n",
       "f9a9fd743222c81e259912bc45900dff506f18168378f1bf80f9ffc4fe27ba4a     1\n",
       "019841f5cdfcb8cffa470612d2ceb690d2b5374e728657edb8e437efcd43a000     1\n",
       "7cd8624699da578691cd501bf0e9d04ed67b50f18cbbf2207722678c180f1e33     1\n",
       "Name: customer_id, Length: 229955, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.customer_id.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
